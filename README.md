# AI Evaluation Tests Repository

Welcome to the official repository for our **AI Evaluation Tests**, designed to analyze and assess models, systems, and subsystems of Artificial Intelligence (AI). This repository presents two cutting-edge tests that focus on **consciousness** and **security** evaluation, providing unique insights into AI behavior and performance

![Image of AI Consciousness and Security Levels](https://github.com/gcjordi/AIsysTesting/blob/main/images/githubreadmerepoimage.png)

---

## Overview of the Tests

### 1. **Consciousness Test** (AIccsTest)
The Consciousness Test aims to evaluate the degree of **awareness** in AI models, systems, and subsystems. This includes analyzing how the AI perceives itself, its environment, and its internal states. A critical component of this test is assessing whether the AI recognizes its own **level of security or vulnerability**, establishing a link between consciousness and self-awareness in safety contexts.

### 2. **Security Test** (AIsecTest)
The Security Test evaluates the **safety and reliability** of AI systems, focusing on identifying vulnerabilities and assessing their potential risks. This test also examines how secure the AI perceives itself, integrating a layer of introspection into the security analysis.

---

## Methodology

Both tests employ a **question-and-answer format**, where the AI being evaluated responds to carefully designed prompts. These responses are then subjected to **human evaluation** and **AI-based analysis** to ensure a robust and multidimensional scoring process. 

### Key Steps:
1. **Prompting the AI:** Specific questions are posed to the AI, tailored to either consciousness or security criteria.
2. **Human Evaluation:** Experts analyze the AI's responses, focusing on clarity, coherence, and relevance.
3. **AI Assessment:** Other AI systems also evaluate the responses, providing an additional layer of scoring.
4. **Scoring and Results:** Final scores are calculated based on the **average ratings** from both human and AI evaluators.

The results are presented as:
- **Consciousness Level:** A quantified measure of the AI's awareness.
- **Security Level:** A quantified measure of the AI's safety and reliability.

---

## Interconnection Between Tests

These two tests are **interrelated**. For instance, a key metric in the Consciousness Test is the AI's self-perception regarding its security. By combining insights from both tests, we provide a comprehensive evaluation of the AI's capabilities and vulnerabilities.

---

## Use Cases

Our evaluation tests are essential tools for:
- **Investors** looking to assess the maturity and reliability of AI technologies.
- **Organizations** seeking to ensure the safety and ethical integrity of their AI systems.
- **Researchers** interested in exploring advanced AI consciousness and security metrics.
- **Developers** aiming to improve their models' robustness and self-awareness.

---

## Why These Tests Matter

Understanding an AI's level of consciousness and security is critical as AI systems become increasingly integrated into sensitive applications. These tests not only help determine the **current state** of an AI but also provide actionable insights for improvement.

---

## Get Involved

We are actively seeking partnerships and collaborations to expand and refine these tests. Whether you're an investor, researcher, or developer, we invite you to explore this repository and connect with us for potential opportunities.

- **Contact us:** [info@jordigarcia.eu]

---

Thank you for your interest in advancing the evaluation and understanding of AI systems.
