I have developed two tests to analyze and evaluate AI models, systems and subsystems. The first test focuses on analyzing the degree of awareness of each model, system or subsystem evaluated and the second test focuses on the security of each model, system or subsystem being analyzed. The tests are interrelated, since one of the points of the awareness test is to evaluate how aware the AI ​​itself is of how safe or unsafe it is. The methodology of the tests is based on the question / answer format to the model, system or subsystem being evaluated and the subsequent human evaluation of the AI's perceptions. The results of the tests (and which determine the degree of awareness of the AI ​​in one test and the degree of security of the AI ​​in the other test) are based on an average of all the scores given by both humans and other AIs that analyze, judge and score the AI's responses.
